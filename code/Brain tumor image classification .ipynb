{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecc6e94",
   "metadata": {},
   "source": [
    "# Image classification of brain tumor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83fba31",
   "metadata": {},
   "source": [
    "In this project, I train a machine learning model to classify brain scans as having tumors or not.\n",
    "\n",
    "Brain tumor classification using image data is an important area of research and medical application. It involves analyzing medical images, such as MRI (Magnetic Resonance Imaging) scans, to identify and classify different types of brain tumors. This field has gained significant attention due to its potential to assist in early detection, accurate diagnosis, and personalized treatment planning for brain tumor patients.\n",
    "\n",
    "The motivation behind such classification using image data is multifold. Here are some key reasons:\n",
    "\n",
    "1. Early Detection and Diagnosis: Early detection of brain tumors is crucial for timely intervention and improved patient outcomes. By analyzing medical images, machine learning algorithms can assist radiologists in identifying potential tumor regions that may be missed by the human eye. This can lead to earlier diagnosis, enabling prompt treatment and potentially better prognosis for patients.\n",
    "</br>\n",
    "\n",
    "2. Improved Accuracy and Objectivity: Human interpretation of medical images can be subjective and prone to errors. By leveraging machine learning techniques, the classification process can be made more objective and consistent. Algorithms can learn from large datasets, capturing intricate patterns and features that may not be immediately evident to human observers. This can enhance the accuracy and reliability of tumor classification.\n",
    "</br>\n",
    "\n",
    "3. Treatment Planning and Personalized Medicine: Different types of brain tumors may require distinct treatment approaches. Accurate classification of brain tumors based on their imaging characteristics can aid in treatment planning. It can provide valuable information about tumor size, location, invasiveness, and other important factors, enabling healthcare professionals to devise personalized treatment strategies for individual patients.\n",
    "</br>\n",
    "\n",
    "4. Research and Clinical Decision Support: Brain tumor classification using image data contributes to ongoing research efforts and the accumulation of knowledge in the field of neuro-oncology. The insights gained from analyzing large datasets can help researchers understand tumor behavior, treatment responses, and develop novel therapeutic approaches. Moreover, the use of machine learning algorithms as decision support tools can assist radiologists and oncologists in making more informed clinical decisions.\n",
    "</br>\n",
    "\n",
    "5. Automation and Efficiency: Analyzing medical images for tumor classification is a time-consuming task for radiologists and clinicians. By automating this process with machine learning models, the workload can be reduced, allowing healthcare professionals to focus on other critical aspects of patient care. This can potentially enhance overall workflow efficiency and patient management.\n",
    "</br>\n",
    "\n",
    "The dataset used for this project is obtained from Kaggle: https://www.kaggle.com/datasets/ahmedhamada0/brain-tumor-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0e5298",
   "metadata": {},
   "source": [
    "We will begin by importing some useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5f0583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image                                  # we use this here to convert images to RGB\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split   # for splitting dataset into train and test sets\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import normalize\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243a1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set path to directory containing the images\n",
    "image_dir = 'datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aa1a37",
   "metadata": {},
   "source": [
    "Our image directory 'datasets' consists of two sub-directories. One directory contains images with no tumors and the second those with tumors. We will now list all image files in these two directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5af87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tumor_images = os.listdir(image_dir +'no/')\n",
    "yes_tumor_images = os.listdir(image_dir + 'yes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea9c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will split our data into the dependent and independent variables and we need to create two empty lists to store these \n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# read all jpg image files in the no_tumor_images directory (and yes_tumor directory), convert them to RGB and store\n",
    "# resulting image in the images list. Also store their corresponding labels in the labels list\n",
    "\n",
    "# reading files in the no_tumor_images directory\n",
    "for i, image_jpg in enumerate(no_tumor_images):\n",
    "    if(image_jpg.split('.')[1]=='jpg'):\n",
    "        image = cv2.imread(image_dir+'no/'+image_jpg)\n",
    "        # convert image to RGB using PIL\n",
    "        image = Image.fromarray(image,\"RGB\")\n",
    "        # Resize the image to a fixed size (e.g., we will use a size of 64x64)\n",
    "        image = image.resize((64, 64))\n",
    "        # convert image to a numpy array and append image to images list\n",
    "        images.append(np.array(image))\n",
    "        # Add label to the labels list. The label in this case is 0 since the image has no tumor \n",
    "        labels.append(0)\n",
    "        \n",
    "# reading files in the yes_tumor_images directory\n",
    "for i, image_jpg in enumerate(yes_tumor_images):\n",
    "    if(image_jpg.split('.')[1]=='jpg'):\n",
    "        image = cv2.imread(image_dir+'yes/'+image_jpg)\n",
    "        # convert image to RGB using PIL\n",
    "        image = Image.fromarray(image,\"RGB\")\n",
    "        # Resize the image to a fixed size (e.g., we will use a size of 64x64)\n",
    "        image = image.resize((64, 64))\n",
    "        # convert image to a numpy array and append image to images list\n",
    "        images.append(np.array(image))\n",
    "        # Add label to the labels list. The label in this case is 0 since the image has no tumor \n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa3ad8",
   "metadata": {},
   "source": [
    "### Some visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5cf55",
   "metadata": {},
   "source": [
    "Let's visualize some of the images in the images list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199758ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,15));\n",
    "for i,j in enumerate(images):\n",
    "    if i<4:\n",
    "        plt.subplot(1,4,i+1)\n",
    "        plt.imshow(j);\n",
    "        plt.xlabel(labels[i]);\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        break\n",
    "# the x-axis of the images show the labels. Remember 0 means no tumor and 1 means the imags has a tumor\n",
    "\n",
    "plt.savefig('images.jpg', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca28d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we convert the images and labels lists into numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into train and validation sets, we split with 80% of the data as training set and the remaining 20% for\n",
    "## validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "# let's check the shape of the train and and validation sets\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1125f5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data\n",
    "X_train=normalize(X_train, axis=1)\n",
    "X_val =normalize(X_val, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4649891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model (we first use a binary classifier)\n",
    "model1 =  Sequential()\n",
    "\n",
    "model1.add(Conv2D(32,(3,3),input_shape=(64,64,3)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(32,(3,3), kernel_initializer = 'he_uniform'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Conv2D(64,(3,3), kernel_initializer = 'he_uniform'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(64))\n",
    "model1.add(Activation('relu'))\n",
    "# Define the output layer and add droupout to prevent overfitting\n",
    "# for our output layer, dense = 1 since we have a binary classification problem and for this we use a sigmoid activation funtion\n",
    "# for categorical cross entropy for example dense would have been 2 and we would have used a softmax activation function\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1))\n",
    "# add activation function\n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model1.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model1_his = model1.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val), verbose = 1,shuffle=False)\n",
    "\n",
    "# Save the model\n",
    "model1.save('BTEpochs_30.keras')\n",
    "\n",
    "# we have a good model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a13102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values for binary classification model\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5), dpi = 300)\n",
    "ax[0].plot(model1_his.history['accuracy'])\n",
    "ax[0].plot(model1_his.history['val_accuracy'])\n",
    "ax[0].set_title('Training and validation accuracy for binary classification model')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "ax[1].plot(model1_his.history['loss'])\n",
    "ax[1].plot(model1_his.history['val_loss'])\n",
    "ax[1].set_title('Training and validation loss for binary classification model')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "plt.tight_layout(pad =3.0) \n",
    "\n",
    "plt.savefig('train_ValLossBClass.jpg', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bda2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us also build the model using cross entropy but first, we will convert our training sets into a categorical format\n",
    "y_train  = to_categorical(y_train, num_classes = 2)\n",
    "y_val  = to_categorical(y_val, num_classes = 2)\n",
    "\n",
    "model2 =  Sequential()\n",
    "\n",
    "model2.add(Conv2D(32,(3,3),input_shape=(64,64,3)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Conv2D(32,(3,3), kernel_initializer = 'he_uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Conv2D(64,(3,3), kernel_initializer = 'he_uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64))\n",
    "model2.add(Activation('relu'))\n",
    "# output layer. Add droupout to prevent overfitting\n",
    "# for our output, we now use 2 dense layer and we use the softmax activation function\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(2))\n",
    "# add activation function\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model2_his = model2.fit(X_train, y_train, batch_size=32, epochs=30, validation_data=(X_val, y_val), verbose = 1,shuffle=False)\n",
    "\n",
    "# Save the model\n",
    "model2.save('BT_CEnt_Categorical_epochs_30.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb34821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training & validation loss values for categorical cross entropy model\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5), dpi = 300)\n",
    "ax[0].plot(model2_his.history['accuracy'])\n",
    "ax[0].plot(model2_his.history['val_accuracy'])\n",
    "ax[0].set_title('Training and validation accuracy for categorical cross entropy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "ax[1].plot(model2_his.history['loss'])\n",
    "ax[1].plot(model2_his.history['val_loss'])\n",
    "ax[1].set_title('Training and validation loss for categorical cross entropy')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "plt.tight_layout(pad =3.0) \n",
    "\n",
    "plt.savefig('train_ValLossCatEnt.jpg', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757121d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "# as an example, we will try to predict the class of two different images, one with tumor and the other without\n",
    "# but first let us load these images from the pred directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95be9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file 1 (with no tumor) from the test directory\n",
    "image_pred_no = cv2.imread('pred/pred0.jpg')\n",
    "# convert image to RGB using PIL\n",
    "image_p_no = Image.fromarray(image_pred_no)\n",
    "# Resize the image to a fixed size (e.g., we will use a size of 64x64)\n",
    "image_p_no = image_p_no.resize((64, 64))\n",
    "# convert image to a numpy array \n",
    "image_p_no = np.array(image_p_no)\n",
    "# expand the dimension of the image\n",
    "input_p_no = np.expand_dims(image_p_no, axis= 0)\n",
    "\n",
    "# read file 6 (with tumor) from the test directory\n",
    "image_pred_yes = cv2.imread('pred/pred5.jpg')\n",
    "# convert image to RGB using PIL\n",
    "image_p_yes = Image.fromarray(image_pred_yes)\n",
    "# Resize the image to a fixed size (e.g., we will use a size of 64x64)\n",
    "image_p_yes = image_p_yes.resize((64, 64))\n",
    "# convert image to a numpy array \n",
    "image_p_yes = np.array(image_p_yes)\n",
    "# expand the dimension of the image\n",
    "input_p_yes=np.expand_dims(image_p_yes, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d253b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class of the images based on the model\n",
    "#result_no_model1 = model.predict_classes(image_p_no)\n",
    "result_no_model1 =np.argmax(model1.predict(input_p_no),axis=1)\n",
    "result_no_model2 =np.argmax(model2.predict(input_p_no),axis=1)\n",
    "#result_no_model2 = model2.predict_classes(image_p_no)\n",
    "\n",
    "result_yes_model1 =np.argmax(model1.predict(input_p_yes),axis=1)\n",
    "result_yes_model2 =np.argmax(model2.predict(input_p_yes),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273440e0",
   "metadata": {},
   "source": [
    "Our categorical cross entropy model seem to behave better than the binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc60653",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('N.B, if image has no tumor, label is 0, otherwise, labe is 1\\n')\n",
    "print('model 1 predicts image with no tumor has having label, ',result_no_model1)\n",
    "print('model 2 predicts image with no tumor has having label, ',result_no_model2)\n",
    "print('\\n')\n",
    "print('model 1 predicts image with tumor has having label, ',result_yes_model1)\n",
    "print('model 2 predicts image with tumor has having label, ',result_yes_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b9e5b",
   "metadata": {},
   "source": [
    "Our categorical cross entropy model seem to behave better than the binary cross entropy so we will stick with this going forward. Next we will use our model to classify all images in the test set and visualize a few of this to see how well our model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67ff0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set directory containing test set\n",
    "test_images = os.listdir('pred/')\n",
    "images_test = []\n",
    "images_testt = []\n",
    "\n",
    "# reading images in the testset directory\n",
    "for i, image_jpg in enumerate(test_images):\n",
    "    if(image_jpg.split('.')[1]=='jpg'):\n",
    "        image = cv2.imread('pred/'+image_jpg)\n",
    "        # convert image to RGB using PIL\n",
    "        image = Image.fromarray(image)\n",
    "        # Resize the image to a fixed size (e.g., we will use a size of 128x128)\n",
    "        image = image.resize((64, 64))\n",
    "        # convert image to a numpy array and normalize pixel values to range between 0 and 1\n",
    "        # to do this, we divide each pixel value by 255 since we have an 8-bit image\n",
    "        #image = np.array(image)/255.0\n",
    "        # append image to images list\n",
    "        #image = np.expand_dims(image, axis= 0)\n",
    "        images_test.append(np.array(image))\n",
    "        images_testt.append(np.expand_dims(np.array(image), axis= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cc780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "predictions = [np.argmax(model2.predict(images_testt[i]),axis=1) for i in range(len(images_testt))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d12b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first 1o images in images_testt and add the corresponding predicted label on the x axis \n",
    "plt.figure(figsize = (15,15));\n",
    "for i,j in enumerate(images_test):\n",
    "    if i<10:\n",
    "        plt.subplot(1,10,i+1)\n",
    "        plt.imshow(j);\n",
    "        plt.xlabel(predictions[i]);\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "plt.savefig('First_tenImages_TestSet.jpg', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143fe806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first 30 images and labels\n",
    "fig, ax = plt.subplots(3,10, figsize=(20,8), dpi = 500)\n",
    "\n",
    "for i in range(10):\n",
    "    ax[0,i].imshow(images_test[i])\n",
    "    ax[0,i].set_xlabel(predictions[i])\n",
    "    \n",
    "    ax[1,i].imshow(images_test[i+10])\n",
    "    ax[1,i].set_xlabel(predictions[i+10])\n",
    "    \n",
    "    ax[2,i].imshow(images_test[i+20])\n",
    "    ax[2,i].set_xlabel(predictions[i+20])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('First_30Images_TestSet.jpg', dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c472c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58b37e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
